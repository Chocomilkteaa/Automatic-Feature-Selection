{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import arff\n",
    "import os\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "n_cpu = os.cpu_count() - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif, mutual_info_classif, SequentialFeatureSelector, RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearnex import patch_sklearn\n",
    "\n",
    "patch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processNSLKDD():\n",
    "    arff_train = arff.loadarff('./Data/nsl-kdd/KDDTrain+.arff')\n",
    "    arff_test = arff.loadarff('./Data/nsl-kdd/KDDTest+.arff')\n",
    "    train_data = pd.DataFrame(arff_train[0])\n",
    "    test_data = pd.DataFrame(arff_test[0])\n",
    "    \n",
    "    for f in test_data.select_dtypes(include='O').columns:\n",
    "        train_data[f] = train_data[f].str.decode(encoding='utf-8')\n",
    "        test_data[f] = test_data[f].str.decode(encoding='utf-8')\n",
    "\n",
    "    for f in ['land', 'logged_in', 'is_host_login', 'is_guest_login']:\n",
    "        train_data[f] = train_data[f].map({'0': 0, '1': 1}).astype(int)\n",
    "        test_data[f] = test_data[f].map({'0': 0, '1': 1}).astype(int)\n",
    "\n",
    "    X_train = train_data.drop(['class', 'num_outbound_cmds'], axis=1).select_dtypes(include='number')\n",
    "\n",
    "    X_max, X_min = X_train.max(axis=0), X_train.min(axis=0)\n",
    "    X_train = (X_train - X_min) / (X_max - X_min)\n",
    "\n",
    "    Y_train = train_data['class'].map({'normal': 1, 'anomaly': 0})\n",
    "\n",
    "    X_test = test_data.drop(['class', 'num_outbound_cmds'], axis=1).select_dtypes(include='number')\n",
    "\n",
    "    X_test = (X_test - X_min) / (X_max - X_min)\n",
    "    X_test.clip(0, 1)\n",
    "\n",
    "    Y_test = test_data['class'].map({'normal': 1, 'anomaly': 0})\n",
    "\n",
    "    return X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_test, Y_test = processNSLKDD()\n",
    "print(X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation-Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectByCFS(X_train, Y_train):\n",
    "    def getMerit(subset):\n",
    "        k = len(subset)\n",
    "        rcf = corr_target.loc[subset].mean()\n",
    "\n",
    "        corr_cur = X_train[subset].corr().abs().values\n",
    "        rff = corr_cur[np.tril_indices_from(corr_cur)].mean()\n",
    "\n",
    "        merit = (k * rcf) / np.sqrt(k + k * (k-1) * rff)\n",
    "\n",
    "        return merit\n",
    "\n",
    "    corr_target = X_train.corrwith(Y_train).abs().sort_values(ascending=False)\n",
    "\n",
    "    columns_to_select = X_train.columns.tolist()\n",
    "    cur_merit = getMerit(columns_to_select)\n",
    "    n =  len(X_train.columns)\n",
    "\n",
    "    while len(columns_to_select) > 1:\n",
    "        merits = pd.DataFrame(columns=['Feature', 'Merit'])\n",
    "        for f in columns_to_select:\n",
    "            cur_set = [ff for ff in columns_to_select if ff != f]\n",
    "            k = len(cur_set)\n",
    "\n",
    "            rcf = corr_target.loc[cur_set].mean()\n",
    "\n",
    "            corr_cur = X_train[cur_set].corr().abs().values\n",
    "            rff = corr_cur[np.tril_indices_from(corr_cur)].mean()\n",
    "\n",
    "            merit = (k * rcf) / np.sqrt(k + k * (k-1) * rff)\n",
    "            \n",
    "            merits.loc[len(merits)] = [f, merit]\n",
    "        \n",
    "        merits = merits.sort_values(by='Merit', ascending=False)\n",
    "\n",
    "        if merits.loc[0, 'Merit'] > cur_merit:\n",
    "            cur_merit = merits.loc[0, 'Merit']\n",
    "            columns_to_select.remove(merits.loc[0, 'Feature'])\n",
    "        else:\n",
    "            break\n",
    "\n",
    "        del merits\n",
    "\n",
    "    print(columns_to_select, cur_merit)\n",
    "\n",
    "    return columns_to_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_select = selectByCFS(X_train, Y_train)\n",
    "columns_to_select"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectByUFS(X_train, Y_train):\n",
    "    selector = SelectKBest(score_func=mutual_info_classif, k='all')\n",
    "    selector.fit(X_train, Y_train)\n",
    "\n",
    "    return X_train.columns[np.argsort(-selector.scores_)].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_by_UFS = selectByUFS(X_train.iloc[:100], Y_train.iloc[:100])\n",
    "columns_by_UFS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectBySBS(X_train, Y_train):\n",
    "    model = RandomForestClassifier(random_state=0, oob_score=True)\n",
    "    cv = StratifiedKFold(shuffle=True, random_state=0)\n",
    "    n_features = X_train.shape[1]\n",
    "    columns_by_SBS = []\n",
    "\n",
    "    for i in range(n_features-1):\n",
    "        X_train_sub = X_train.drop(columns_by_SBS, axis=1)\n",
    "        selector = SequentialFeatureSelector(model, n_features_to_select=X_train_sub.shape[1]-1, direction='backward', scoring='f1', cv=cv, n_jobs=n_cpu)\n",
    "        selector.fit(X_train_sub, Y_train)\n",
    "        columns_by_SBS.insert(0, X_train_sub.columns[~selector.get_support()][0])\n",
    "        del X_train_sub\n",
    "\n",
    "    columns_by_SBS.insert(0, X_train.columns.drop(columns_by_SBS)[0])\n",
    "\n",
    "    return columns_by_SBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_by_SBS = selectBySBS(X_train.iloc[:100], Y_train.iloc[:100])\n",
    "columns_by_SBS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectByRFE(X_train, Y_train):\n",
    "    model = RandomForestClassifier(random_state=0, oob_score=True, n_jobs=n_cpu)\n",
    "\n",
    "    selector = RFE(model, n_features_to_select=1)\n",
    "    selector.fit(X_train, Y_train)\n",
    "\n",
    "    return X_train.columns[np.argsort(selector.ranking_)].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_by_RFE = selectByRFE(X_train.iloc[:100], Y_train.iloc[:100])\n",
    "columns_by_RFE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectByImportance(X_train, Y_train):\n",
    "    model = RandomForestClassifier(random_state=0, oob_score=True, n_jobs=n_cpu)\n",
    "    model.fit(X_train, Y_train)\n",
    "\n",
    "    return X_train.columns[np.argsort(-model.feature_importances_)].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_by_imp = selectByImportance(X_train.iloc[:100], Y_train.iloc[:100])\n",
    "columns_by_imp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(columns_by_UFS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectBySet(columns_by_UFS, columns_by_SBS, columns_by_RFE, columns_by_imp):    \n",
    "    n_features = len(columns_by_UFS)\n",
    "\n",
    "    columns_by_union = []\n",
    "    columns_by_intersection = []\n",
    "    columns_by_quorum = []\n",
    "\n",
    "    for i in range(1, n_features+1):\n",
    "        columns_by_union.append(list(set().union(columns_by_UFS[:i], columns_by_SBS[:i], columns_by_RFE[:i], columns_by_imp[:i])))\n",
    "        columns_by_intersection.append(list(set(columns_by_UFS[:i]).intersection(columns_by_SBS[:i], columns_by_RFE[:i], columns_by_imp[:i])))\n",
    "        columns_sum = columns_by_UFS[:i] + columns_by_SBS[:i] + columns_by_RFE[:i] + columns_by_imp[:i]\n",
    "        columns_by_quorum.append([f for f in set(columns_sum) if columns_sum.count(f) > 2])\n",
    "\n",
    "    return columns_by_union, columns_by_intersection, columns_by_quorum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_by_union, columns_by_intersection, columns_by_quorum = selectBySet(columns_by_UFS, columns_by_SBS, columns_by_RFE, columns_by_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(columns_by_union[0])\n",
    "print([len(i) for i in columns_by_union])\n",
    "print([len(i) for i in columns_by_intersection])\n",
    "print([len(i) for i in columns_by_quorum])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Greedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectByGreedy(X_train, Y_train, columns_by_UFS):    \n",
    "    model = RandomForestClassifier(random_state=0, oob_score=True)\n",
    "    cv = StratifiedKFold(shuffle=True, random_state=0)\n",
    "\n",
    "    n_features = X_train.shape[1]\n",
    "\n",
    "    greedy_features = []\n",
    "\n",
    "    for i in range(n_features-1):\n",
    "        candidates = [columns_by_UFS[0]]\n",
    "\n",
    "        X_train_sub = X_train.drop(greedy_features, axis=1)\n",
    "\n",
    "        selector = SequentialFeatureSelector(model, n_features_to_select=X_train_sub.shape[1]-1, direction='backward', scoring='f1', cv=cv, n_jobs=n_cpu)\n",
    "        selector.fit(X_train_sub, Y_train)\n",
    "        candidates.append(X_train_sub.columns[~selector.get_support()][0])\n",
    "\n",
    "        selector = RFE(model, n_features_to_select=X_train_sub.shape[1]-1)\n",
    "        selector.fit(X_train_sub, Y_train)\n",
    "        candidates.append(X_train_sub.columns[~selector.get_support()][0])\n",
    "\n",
    "        model_imp = clone(model)\n",
    "        model_imp.fit(X_train_sub, Y_train)\n",
    "        candidates.append(X_train_sub.columns[np.argsort(model_imp.feature_importances_)][0])\n",
    "\n",
    "        scores = []\n",
    "        for f in candidates:\n",
    "            cv_score = cross_val_score(model, X_train_sub.drop(f, axis=1), Y_train, scoring='f1', cv=cv, n_jobs=n_cpu)\n",
    "            scores.append(cv_score.mean())\n",
    "\n",
    "        feature_to_remove = candidates[np.argmax(scores)]\n",
    "        greedy_features.append(feature_to_remove)\n",
    "        columns_by_UFS.remove(feature_to_remove)  \n",
    "\n",
    "        print(feature_to_remove)  \n",
    "\n",
    "    greedy_features.append(X_train.columns.drop(greedy_features)[0])\n",
    "    greedy_features.reverse()\n",
    "\n",
    "    return greedy_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_by_greedy = selectByGreedy(X_train.iloc[:100], Y_train.iloc[:100], columns_by_UFS.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_result = pd.DataFrame(columns=['UFS', 'SBS', 'RFE', 'Importance', 'Union', 'Intersection', 'Quorum', 'Greedy'])\n",
    "for f, l in zip(columns_result.columns, [columns_by_UFS, columns_by_SBS, columns_by_RFE, columns_by_imp, columns_by_union, columns_by_intersection, columns_by_quorum, columns_by_greedy]):\n",
    "    columns_result[f] = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_result.to_pickle('./Result/columns_result.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
